{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbhsxJM0o1KT",
        "outputId": "903b2460-d77e-4b72-9c2d-5df841486af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 24 22:25:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "\n",
        "!pip install ultralytics==8.0.58 roboflow numpy==1.24.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1AEEde0GpgRl",
        "outputId": "6222eb9c-dc63-4ab7-b9d2-95389581348a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "Successfully installed numpy-1.26.4\n",
            "Collecting ultralytics==8.0.58\n",
            "  Downloading ultralytics-8.0.58-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.8/486.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting roboflow\n",
            "  Downloading roboflow-1.1.25-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.24.2\n",
            "  Downloading numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (4.66.2)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (0.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.58) (5.9.5)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.0.58)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk (from ultralytics==8.0.58)\n",
            "  Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.58) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.58) (4.50.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.58) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.58) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.58) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.58) (3.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.58) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->ultralytics==8.0.58)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->ultralytics==8.0.58) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics==8.0.58) (1.3.0)\n",
            "Installing collected packages: python-magic, python-dotenv, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, idna, cycler, chardet, certifi, sentry-sdk, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, requests-toolbelt, nvidia-cusolver-cu12, roboflow, thop, ultralytics\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 numpy-1.24.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.25 sentry-sdk-1.43.0 thop-0.1.1.post2209072238 ultralytics-8.0.58\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "numpy"
                ]
              },
              "id": "28c4089adcb14685867a0039ba28ad03"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qdvk6eMMpovd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0230004b-12b9-441f-919c-2621ed05dd8b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model_path = 'yolov8x-cls.pt'  # @param {type:\"string\"}\n",
        "data_path = '/content/drive/MyDrive/Skin_Burn'  # @param {type:\"string\"}\n",
        "\n",
        "epochs = 30  # @param {type:\"integer\"}\n",
        "img_size = 640  # @param {type:\"integer\"}\n",
        "amp = True # @param {type:\"boolean\"}\n",
        "cache = True # @param {type:\"boolean\"}\n",
        "resume = False # @param {type:\"boolean\"}\n",
        "\n",
        "patience = 10 # @param {type:\"integer\"}\n",
        "# Create YOLO model and train\n",
        "model = YOLO(model_path)\n",
        "model.train(data=data_path, epochs=epochs, imgsz=img_size, amp = amp, cache = cache, patience=patience, resume = resume)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eM1hGBKLkRUC",
        "outputId": "c404bd85-7902-4d2e-f487-1d092690f33a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "New https://pypi.org/project/ultralytics/8.1.33 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.58 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8x-cls.pt, data=/content/drive/MyDrive/Skin_Burn, epochs=30, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=True, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.Conv                  [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.Conv                  [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.C2f                   [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.Conv                  [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.C2f                   [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.Conv                  [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.C2f                   [640, 640, 6, True]           \n",
            "  7                  -1  1   7375360  ultralytics.nn.modules.Conv                  [640, 1280, 3, 2]             \n",
            "  8                  -1  3  27865600  ultralytics.nn.modules.C2f                   [1280, 1280, 3, True]         \n",
            "  9                  -1  1   1644803  ultralytics.nn.modules.Classify              [1280, 3]                     \n",
            "YOLOv8x-cls summary: 183 layers, 56145683 parameters, 56145683 gradients, 154.3 GFLOPs\n",
            "Transferred 300/302 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/30      2.32G     0.2448          6        224: 100%|██████████| 345/345 [12:45<00:00,  2.22s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:23<00:00,  3.39s/it]\n",
            "                   all      0.566          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/30      2.51G     0.2352          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  3.67it/s]\n",
            "                   all      0.617          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/30      2.58G     0.2297          6        224: 100%|██████████| 345/345 [00:59<00:00,  5.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.89it/s]\n",
            "                   all      0.612          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/30      2.58G      0.223          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.68it/s]\n",
            "                   all      0.697          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/30      2.64G     0.2158          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.59it/s]\n",
            "                   all      0.709          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/30      2.64G     0.2109          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.92it/s]\n",
            "                   all      0.732          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/30      2.64G     0.2073          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  3.82it/s]\n",
            "                   all      0.727          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/30      2.64G     0.2027          6        224: 100%|██████████| 345/345 [00:57<00:00,  6.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.97it/s]\n",
            "                   all      0.752          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/30      2.64G     0.2021          6        224: 100%|██████████| 345/345 [00:57<00:00,  6.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  5.01it/s]\n",
            "                   all      0.734          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/30      2.64G     0.2005          6        224: 100%|██████████| 345/345 [00:59<00:00,  5.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.75it/s]\n",
            "                   all      0.732          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      11/30      2.64G     0.1991          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  3.85it/s]\n",
            "                   all      0.754          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      12/30      2.64G     0.1972          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  3.94it/s]\n",
            "                   all      0.754          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      13/30      2.64G     0.1958          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.74it/s]\n",
            "                   all      0.774          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      14/30      2.64G     0.1965          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.73it/s]\n",
            "                   all      0.749          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      15/30      2.64G     0.1935          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.65it/s]\n",
            "                   all      0.734          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      16/30      2.64G     0.1909          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  5.04it/s]\n",
            "                   all      0.742          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      17/30      2.64G     0.1888          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  3.27it/s]\n",
            "                   all      0.754          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      18/30      2.64G     0.1899          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  3.03it/s]\n",
            "                   all      0.794          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      19/30      2.64G     0.1857          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  2.95it/s]\n",
            "                   all      0.754          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      20/30      2.64G     0.1845          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  2.91it/s]\n",
            "                   all      0.769          1\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      21/30      2.64G     0.1848          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.65it/s]\n",
            "                   all      0.759          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      22/30      2.64G     0.1828          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.99it/s]\n",
            "                   all      0.772          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      23/30      2.64G     0.1796          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.97it/s]\n",
            "                   all      0.782          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      24/30      2.64G     0.1779          6        224: 100%|██████████| 345/345 [00:58<00:00,  5.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  2.91it/s]\n",
            "                   all      0.774          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      25/30      2.64G     0.1799          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  3.05it/s]\n",
            "                   all      0.762          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      26/30      2.64G     0.1793          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:02<00:00,  3.12it/s]\n",
            "                   all      0.802          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      27/30      2.64G     0.1769          6        224: 100%|██████████| 345/345 [00:57<00:00,  6.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.04it/s]\n",
            "                   all      0.799          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      28/30      2.64G     0.1757          6        224: 100%|██████████| 345/345 [00:59<00:00,  5.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.87it/s]\n",
            "                   all      0.779          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      29/30      2.64G     0.1728          6        224: 100%|██████████| 345/345 [00:57<00:00,  6.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  4.80it/s]\n",
            "                   all      0.789          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      30/30      2.64G     0.1699          6        224: 100%|██████████| 345/345 [00:57<00:00,  5.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 7/7 [00:01<00:00,  5.03it/s]\n",
            "                   all      0.774          1\n",
            "\n",
            "30 epochs completed in 0.758 hours.\n",
            "Optimizer stripped from runs/classify/train2/weights/last.pt, 112.5MB\n",
            "Optimizer stripped from runs/classify/train2/weights/best.pt, 112.5MB\n",
            "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}